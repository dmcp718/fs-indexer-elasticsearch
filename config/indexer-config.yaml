# Configuration for the file indexer

# =============================================
# Async Worker Setup Instructions
# =============================================
# To use async checksum calculation:
# 1. Set checksum_mode: "async" in this config
# 2. Start the Redis server and worker process:
#    ./venv/bin/python3 -m fs_indexer.run_checksum_worker
# 3. In another terminal, run the main indexer:
#    ./venv/bin/python3 -m fs_indexer.main
#
# The worker will:
# - Calculate checksums in the background
# - Update the database automatically
# - Handle Redis connection and recovery
# - Process files in batches for efficiency
#
# Monitor the worker logs for progress and any errors
# =============================================

# LucidLink Filespace configuration
lucidlink_filespace:
  enabled: true
  # Skip generating direct links for files (faster indexing)
  skip_direct_links: false
  # LucidLink filespace version (2 or 3)
  lucidlink_version: 3
  # LucidLink port
  port: 9778
  # Calculate directory sizes (may slow down processing)
  calculate_directory_sizes: true
  
  # Version-specific settings
  v2_settings:
    # Cache fsentry_ids for faster direct link generation
    enable_fsentry_cache: true
    # Cache TTL in hours
    cache_ttl_hours: 1
    # Maximum concurrent API requests for ID lookup
    max_concurrent_requests: 20
    # Retry settings for API calls
    retry_attempts: 3
    retry_delay_seconds: 1
    
  v3_settings:
    # Maximum concurrent API requests for direct links
    max_concurrent_requests: 50
    # Retry settings for API calls
    retry_attempts: 3
    retry_delay_seconds: 1
    # Batch size for direct link requests
    batch_size: 100

# =============================================

# Root path to start indexing from (optional, can be provided via --root-path argument)
root_path: "/Volumes/dmpfs/production/00_Media"

# =============================================
# Elasticsearch configuration
# =============================================
elasticsearch:
  host: localhost
  port: 9200
  username: ""  # Leave empty for no authentication
  password: ""  # Leave empty for no authentication
  index_name: filespace # For LucidLink filespaces, app uses filespace-domain for index name
  ssl: false
  
  # Bulk indexing settings
  bulk_size: 5000
  max_retries: 3
  timeout_seconds: 300
  retry_on_timeout: true

# =============================================
# Operation Mode
# =============================================
# Available modes:
# - elasticsearch: Run indexer and send records to Elasticsearch (default)
# - index-only: Run indexer only, do not send records to Elasticsearch
mode: elasticsearch

# =============================================
# Database configuration
# =============================================
database:
  connection:
    url: "duckdb:///data/fs_index.duckdb"
    options:
      memory_limit: "4GB"
      threads: 4
      temp_directory: "./.tmp"
      checkpoint_on_shutdown: true
      compression: "lz4"
      
  # Table-specific settings
  tables:
    direct_links:
      # Vacuum settings
      auto_vacuum: true
      vacuum_threshold: 10000
      # Index settings
      create_indexes: true
      index_types: ["last_updated", "fsentry_id"]

# =============================================
# Performance tuning
# =============================================
performance:
  # Database settings
  batch_size: 1000
  db_pool_size: 1
  db_max_overflow: 0
  read_buffer_size: 268435456
  max_workers: 32
  
  # Memory settings
  mmap_size: 2147483648
  
  # File scanning
  scan_chunk_size: 25000  # Adjusted for our dataset size
  parallel_scan: true
  
  # Direct link settings
  direct_link_batch_size: 100
  direct_link_threads: 4  # API bound, so keep low
  direct_link_queue_size: 10000
  
  # Query optimization
  enable_parallel_scan: true
  vacuum_threshold: 10000
  stats_update_frequency: 5000
  
  # Progress reporting
  progress_interval_seconds: 5
  show_rate_stats: true
  show_memory_stats: true

# =============================================
# Logging configuration
# =============================================
logging:
  # Log level options (from most to least verbose):
  # - "DEBUG": Shows file processing details, API responses, and debug info
  # - "INFO": Shows progress updates, batch processing, and summary stats
  # - "WARNING": Shows when some files in a batch couldn't be processed
  # - "ERROR": Shows only errors that prevent processing
  level: "INFO"
  
  # File logging settings
  file:
    enabled: true
    path: "logs/fs-indexer.log"
    max_size_mb: 10
    backup_count: 5
    
  # Console logging settings
  console:
    enabled: true
    show_timestamps: true
    color: true
    
  # Performance logging
  performance:
    enabled: true
    interval_seconds: 60
    include_memory: true
    include_disk: true

# Checksum calculation mode
# - sync: Calculate checksums immediately (slower indexing)
# - async: Queue checksums for background processing (faster indexing)
# - disabled: Skip checksum calculation
checksum_mode: disabled

# Redis configuration for async operations
redis:
  host: localhost
  port: 16379
  db: 0
  checksum_key_prefix: fs_indexer:checksum
  checksum_ttl: 86400
  worker:
    batch_size: 100
    retry_interval: 1
    max_retries: 5

# Check and remove database records for files that no longer exist
check_missing_files: false

# Skip patterns for file extensions and specific files
skip_patterns:
  extensions:
    - .DS_Store
    - .git
    - .gitignore
    - .svn
    - .hg
    - .idea
    - __pycache__
    - '*.pyc'
    - '*.pyo'
    - '*.pyd'
    - '*.so'
    - '*.dylib'
    - '*.dll'
    - '*.class'
    - '*.o'
    - '*.dbr'
  
  directories:
    - .git
    - .venv
    - env
    - .env
    - '.lucid_audit'
    - '.Trash*'
    - '.Spotlight*'
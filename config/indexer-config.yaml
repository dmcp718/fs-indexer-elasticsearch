# Configuration for the file indexer

# LucidLink Filespace configuration
lucidlink_filespace:
  enabled: true  # Enable LucidLink integration
  lucidlink_version: 3  # LucidLink API version (2 or 3)
  port: 9778  # LucidLink API port
  calculate_directory_sizes: true  # Calculate directory sizes (requires additional processing)
  
  # Version-specific settings
  v2_settings:
    # Cache fsentry_ids for faster direct link generation
    enable_fsentry_cache: true
    # Cache TTL in hours
    cache_ttl_hours: 1
    # Maximum concurrent API requests for ID lookup
    max_concurrent_requests: 20
    # Retry settings for API calls
    retry_attempts: 3
    retry_delay_seconds: 1
    
  v3_settings:
    # Maximum concurrent API requests for direct links
    max_concurrent_requests: 10  # API bound, but increased from 4 for better throughput
    # Retry settings for API calls
    retry_attempts: 5
    retry_delay_seconds: 0.5
    # Batch size for direct link requests
    batch_size: 100000  # Optimized: Larger batch size for better throughput
    # Queue size for async processing
    queue_size: 100000  # Optimized: Larger queue size to match batch size

# =============================================

# Root path to start indexing from (optional, can be provided via --root-path argument)
root_path: ""

# =============================================
# Elasticsearch configuration
# =============================================
elasticsearch:
  host: localhost
  port: 9200
  username: ""  # Leave empty for no authentication
  password: ""  # Leave empty for no authentication
  index_name: filespace # For LucidLink filespaces, app uses filespace-domain for index name
  ssl: false
  
  # Bulk indexing settings
  bulk_size: 100000  # Optimized: Larger batch size for better throughput
  max_retries: 3
  timeout_seconds: 300
  retry_on_timeout: true

# =============================================
# Operation Mode
# =============================================
# Available modes:
# - elasticsearch: Run indexer and send records to Elasticsearch (default)
# - index-only: Run indexer only, do not send records to Elasticsearch
mode: elasticsearch

# =============================================
# Database configuration
# =============================================
database:
  connection:
    url: "duckdb:///data/fs_index.duckdb"
    options:
      memory_limit: "8GB"  # Optimized: Higher memory limit for better caching
      threads: 10  # Match max_workers (CPU cores - 2)
      temp_directory: "./.tmp"
      checkpoint_on_shutdown: true
      compression: "lz4"  # Best balance of speed/compression
      
  # Table-specific settings
  tables:
    direct_links:
      # Vacuum settings
      auto_vacuum: true
      vacuum_threshold: 10000
      # Index settings
      create_indexes: true
      index_types: ["last_updated", "fsentry_id"]

# =============================================
# Performance configuration
# =============================================
performance:
  # Batch sizes for different operations
  batch_sizes:
    scan: 100000  # Optimized: Larger batch size for better throughput
    direct_links: 100000  # Optimized: Larger batch size for better throughput
    elasticsearch: 100000  # Optimized: Larger batch size for better throughput
    
  # Parallel processing settings
  # Note: The actual number of workers will dynamically adjust down to match the number
  # of top-level directories in the root path, which showed ~5% better performance in testing.
  parallel_processing:
    enabled: true
    max_workers: 10  # Maximum workers (CPU cores - 2), will adjust down based on directory count
    batch_size: 100000  # Optimized: Larger batch size for better throughput
    
  # File scanning settings
  scan_chunk_size: 100000  # Aligned with other batch sizes for consistent performance
  
  # Progress reporting
  progress_interval_seconds: 5
  show_rate_stats: true
  show_memory_stats: true

# =============================================
# Skip patterns configuration
# =============================================
skip_patterns:
  # Skip hidden files and directories
  hidden_files: true
  hidden_dirs: true
  # Patterns to skip (glob format)
  patterns:
    - ".DS_Store"
    - ".Spotlight-*"
    - ".fseventsd"
    - ".Trashes"
    - "*.tmp"
    - "*.temp"
    - "*~"
    - ".git"
    - "__pycache__"
    - "*.pyc"
    - "*.pyo"
    - "*.pyd"
    - ".pytest_cache"
    - ".coverage"
    - "htmlcov"
    - ".tox"
    - ".eggs"
    - "*.egg-info"
    - "dist"
    - "build"
    - "node_modules"
    - ".venv"
    - "venv"
    - "env"
    - ".env"
    - ".LP_Store"

# =============================================
# Logging configuration
# =============================================
logging:
  # Log level options (from most to least verbose):
  # - "DEBUG": Shows file processing details, API responses, and debug info
  # - "INFO": Shows progress updates, batch processing, and summary stats
  # - "WARNING": Shows when some files in a batch couldn't be processed
  # - "ERROR": Shows only errors that prevent processing
  level: "INFO"
  
  # File logging settings
  file:
    enabled: true
    path: "logs/fs-indexer.log"
    max_size_mb: 10
    backup_count: 5
    
  # Console logging settings
  console:
    enabled: true
    show_timestamps: true
    color: true
    
  # Performance logging
  performance:
    enabled: true
    interval_seconds: 60
    include_memory: true
    include_disk: true

# Check and remove database records for files that no longer exist
check_missing_files: false